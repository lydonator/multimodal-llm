C:\Users\LydoSr\anaconda3\envs\multimod\Lib\site-packages\transformers\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
2024-09-25 02:50:28,665 - INFO - Loaded audio embeddings from embeddings/audio_embeddings.pt.
2024-09-25 02:51:43,058 - INFO - Loaded transcriptions from E:\Ted\Text Chunks.
2024-09-25 02:51:43,177 - INFO - Loaded 123493 samples from the dataset.
c:\Users\LydoSr\Desktop\multimodal-llm\train.py:63: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()  # For mixed precision
Epoch 1/3
c:\Users\LydoSr\Desktop\multimodal-llm\train.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
C:\Users\LydoSr\anaconda3\envs\multimod\Lib\site-packages\transformers\models\gpt2\modeling_gpt2.py:544: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\cb\pytorch_1000000000000\work\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:555.)
  attn_output = torch.nn.functional.scaled_dot_product_attention(
  Batch 4 Loss: 8.9778
  Batch 8 Loss: 9.0151
  Batch 12 Loss: 9.1458
  Batch 16 Loss: 9.0674
  Batch 20 Loss: 9.2358
  Batch 24 Loss: 9.1811
  Batch 28 Loss: 9.2861
  Batch 32 Loss: 9.0730
  Batch 36 Loss: 9.0163
  Batch 40 Loss: 8.9617
  Batch 44 Loss: 9.1837
  Batch 48 Loss: 8.7067
  Batch 52 Loss: 8.7954
  Batch 56 Loss: 8.9583
  Batch 60 Loss: 9.2129
  Batch 64 Loss: 8.9920
  Batch 68 Loss: 9.0363
  Batch 72 Loss: 9.2200
  Batch 76 Loss: 8.7637
  Batch 80 Loss: 9.0040
  Batch 84 Loss: 8.7673
  Batch 88 Loss: 8.8377
  Batch 92 Loss: 9.2576
  Batch 96 Loss: 8.8122
  Batch 100 Loss: 9.1543
  Batch 104 Loss: 8.9617
  Batch 108 Loss: 9.0448
  Batch 112 Loss: 8.7055
  Batch 116 Loss: 9.2372
  Batch 120 Loss: 9.1441
  Batch 124 Loss: 9.1867
  Batch 128 Loss: 9.1166
  Batch 132 Loss: 9.1301
  Batch 136 Loss: 8.7809
  Batch 140 Loss: 8.9572
  Batch 144 Loss: 8.9953
  Batch 148 Loss: 9.0925
  Batch 152 Loss: 8.8752
  Batch 156 Loss: 9.3137
  Batch 160 Loss: 9.0162
  Batch 164 Loss: 8.9919
  Batch 168 Loss: 8.9716
  Batch 172 Loss: 9.0166
  Batch 176 Loss: 8.6130
  Batch 180 Loss: 8.9734
  Batch 184 Loss: 9.0573
  Batch 188 Loss: 8.5909
  Batch 192 Loss: 8.8611
  Batch 196 Loss: 8.5756
  Batch 200 Loss: 8.8219
  Batch 204 Loss: 9.4527
  Batch 208 Loss: 9.2286
  Batch 212 Loss: 8.8431
  Batch 216 Loss: 9.0432
  Batch 220 Loss: 9.0011
  Batch 224 Loss: 8.8247
  Batch 228 Loss: 8.9107
  Batch 232 Loss: 8.8120
  Batch 236 Loss: 8.5139
  Batch 240 Loss: 8.6258
  Batch 244 Loss: 8.9683
  Batch 248 Loss: 9.1871
  Batch 252 Loss: 8.9885
  Batch 256 Loss: 9.2792
  Batch 260 Loss: 8.7241
  Batch 264 Loss: 8.5299
  Batch 268 Loss: 8.8467
  Batch 272 Loss: 9.0174
  Batch 276 Loss: 8.9149
  Batch 280 Loss: 8.7285
  Batch 284 Loss: 9.1474
  Batch 288 Loss: 9.1130
  Batch 292 Loss: 8.8285
  Batch 296 Loss: 8.5631
  Batch 300 Loss: 8.6518
  Batch 304 Loss: 9.1373
  Batch 308 Loss: 8.2424
  Batch 312 Loss: 8.9235
  Batch 316 Loss: 8.8793
  Batch 320 Loss: 8.8354
  Batch 324 Loss: 8.6591
  Batch 328 Loss: 8.3085
  Batch 332 Loss: 8.3006
  Batch 336 Loss: 8.2673
  Batch 340 Loss: 8.5861
  Batch 344 Loss: 8.7981
  Batch 348 Loss: 8.6230
  Batch 352 Loss: 8.8154
  Batch 356 Loss: 8.6122
  Batch 360 Loss: 8.5089
  Batch 364 Loss: 8.7566
  Batch 368 Loss: 8.5332
  Batch 372 Loss: 8.5007
  Batch 376 Loss: 8.6194
  Batch 380 Loss: 8.3099
  Batch 384 Loss: 8.3849
  Batch 388 Loss: 8.5571
  Batch 392 Loss: 8.3380
  Batch 396 Loss: 8.2807
  Batch 400 Loss: 8.4130
  Batch 404 Loss: 8.2517
  Batch 408 Loss: 8.5132
  Batch 412 Loss: 8.6657
  Batch 416 Loss: 8.3738
  Batch 420 Loss: 8.0179
  Batch 424 Loss: 8.3119
  Batch 428 Loss: 8.3895
  Batch 432 Loss: 8.1428
  Batch 436 Loss: 8.0915
  Batch 440 Loss: 8.3135
  Batch 444 Loss: 7.8319
  Batch 448 Loss: 8.0165
  Batch 452 Loss: 8.2795
  Batch 456 Loss: 7.5242
  Batch 460 Loss: 8.1292
  Batch 464 Loss: 8.0509
  Batch 468 Loss: 8.1253
  Batch 472 Loss: 8.3947
  Batch 476 Loss: 8.1379
  Batch 480 Loss: 8.1800
  Batch 484 Loss: 7.5154
  Batch 488 Loss: 7.7165
  Batch 492 Loss: 8.2448
  Batch 496 Loss: 7.6679
  Batch 500 Loss: 8.2206
  Batch 504 Loss: 7.9836
  Batch 508 Loss: 7.6482
  Batch 512 Loss: 7.5489
  Batch 516 Loss: 7.4093
  Batch 520 Loss: 7.2191
  Batch 524 Loss: 7.2180
  Batch 528 Loss: 7.4813
  Batch 532 Loss: 8.0166
  Batch 536 Loss: 7.8254
  Batch 540 Loss: 7.6748
  Batch 544 Loss: 7.4820
  Batch 548 Loss: 7.2401
  Batch 552 Loss: 7.5090
  Batch 556 Loss: 7.1378
  Batch 560 Loss: 6.6925
  Batch 564 Loss: 7.3410
  Batch 568 Loss: 7.2468
  Batch 572 Loss: 7.5763
  Batch 576 Loss: 6.7479
  Batch 580 Loss: 7.5520
  Batch 584 Loss: 7.1257
  Batch 588 Loss: 6.5824
  Batch 592 Loss: 6.5158
  Batch 596 Loss: 6.0843
  Batch 600 Loss: 6.8484
  Batch 604 Loss: 6.4200
  Batch 608 Loss: 6.3332
  Batch 612 Loss: 6.6169
  Batch 616 Loss: 6.9295
  Batch 620 Loss: 6.7277
  Batch 624 Loss: 6.8723
  Batch 628 Loss: 6.8445
  Batch 632 Loss: 6.6362
  Batch 636 Loss: 6.3120
  Batch 640 Loss: 6.7066
  Batch 644 Loss: 6.5873
  Batch 648 Loss: 6.0212
  Batch 652 Loss: 6.1075
  Batch 656 Loss: 6.4914
  Batch 660 Loss: 5.8512
  Batch 664 Loss: 6.2330
  Batch 668 Loss: 6.3536
  Batch 672 Loss: 5.9973
  Batch 676 Loss: 5.8781
  Batch 680 Loss: 5.8872
  Batch 684 Loss: 6.1274
  Batch 688 Loss: 6.1394
  Batch 692 Loss: 5.6712
  Batch 696 Loss: 6.3268
  Batch 700 Loss: 5.9570
  Batch 704 Loss: 6.5291
  Batch 708 Loss: 5.9141
  Batch 712 Loss: 5.5622
  Batch 716 Loss: 6.5236
  Batch 720 Loss: 5.6324
  Batch 724 Loss: 5.9036
  Batch 728 Loss: 5.2538
  Batch 732 Loss: 5.7212
  Batch 736 Loss: 6.1683
  Batch 740 Loss: 5.4440
  Batch 744 Loss: 6.1346
  Batch 748 Loss: 5.4246
  Batch 752 Loss: 5.7670
  Batch 756 Loss: 5.7885
  Batch 760 Loss: 5.3269
  Batch 764 Loss: 5.4240
  Batch 768 Loss: 5.5877
  Batch 772 Loss: 5.8441
  Batch 776 Loss: 6.0479
  Batch 780 Loss: 5.1212
  Batch 784 Loss: 5.3710
  Batch 788 Loss: 5.3693
  Batch 792 Loss: 5.1660
  Batch 796 Loss: 5.2323
  Batch 800 Loss: 5.6368
  Batch 804 Loss: 5.4633
  Batch 808 Loss: 5.5771
  Batch 812 Loss: 5.4907
  Batch 816 Loss: 5.1845
  Batch 820 Loss: 4.9571
  Batch 824 Loss: 5.8647
  Batch 828 Loss: 5.1182
  Batch 832 Loss: 5.2704
  Batch 836 Loss: 5.9118
  Batch 840 Loss: 5.8307
  Batch 844 Loss: 5.2084
  Batch 848 Loss: 5.0675
  Batch 852 Loss: 5.2939
  Batch 856 Loss: 4.9960
  Batch 860 Loss: 5.9447
  Batch 864 Loss: 5.3653
  Batch 868 Loss: 5.3589
  Batch 872 Loss: 5.0617
  Batch 876 Loss: 5.6514
  Batch 880 Loss: 5.3130
  Batch 884 Loss: 5.0518
  Batch 888 Loss: 5.1693
  Batch 892 Loss: 4.9334
  Batch 896 Loss: 4.8309
  Batch 900 Loss: 4.9578
  Batch 904 Loss: 5.9176
  Batch 908 Loss: 5.7573
  Batch 912 Loss: 5.4177
  Batch 916 Loss: 4.6630
  Batch 920 Loss: 5.6272
  Batch 924 Loss: 4.9338
  Batch 928 Loss: 4.8498
  Batch 932 Loss: 5.1191
  Batch 936 Loss: 5.0421
  Batch 940 Loss: 4.9220
  Batch 944 Loss: 4.9546
  Batch 948 Loss: 5.6124
  Batch 952 Loss: 5.4940
  Batch 956 Loss: 4.9333
  Batch 960 Loss: 5.5171
  Batch 964 Loss: 5.7167
  Batch 968 Loss: 5.1667
  Batch 972 Loss: 4.9936
  Batch 976 Loss: 5.1257
  Batch 980 Loss: 4.5039
  Batch 984 Loss: 4.9368
  Batch 988 Loss: 4.3436
  Batch 992 Loss: 4.3485
  Batch 996 Loss: 5.2631
  Batch 1000 Loss: 4.8213
  Batch 1004 Loss: 4.8999
  Batch 1008 Loss: 4.9477
  Batch 1012 Loss: 4.9809
  Batch 1016 Loss: 5.0074
  Batch 1020 Loss: 5.3306
  Batch 1024 Loss: 5.4423
  Batch 1028 Loss: 4.8599
  Batch 1032 Loss: 4.5779
  Batch 1036 Loss: 4.5140
  Batch 1040 Loss: 4.6190
  Batch 1044 Loss: 5.1539
  Batch 1048 Loss: 4.9241
  Batch 1052 Loss: 4.5885
  Batch 1056 Loss: 4.3913
  Batch 1060 Loss: 4.7468
  Batch 1064 Loss: 4.1315
  Batch 1068 Loss: 4.8438
  Batch 1072 Loss: 4.9940
  Batch 1076 Loss: 5.3731
  Batch 1080 Loss: 4.6522
  Batch 1084 Loss: 4.7120
  Batch 1088 Loss: 4.8001
  Batch 1092 Loss: 4.3905
  Batch 1096 Loss: 4.5401
  Batch 1100 Loss: 4.6284
  Batch 1104 Loss: 4.2507
  Batch 1108 Loss: 3.9678
  Batch 1112 Loss: 4.5630
  Batch 1116 Loss: 5.1127
  Batch 1120 Loss: 4.1803
  Batch 1124 Loss: 4.6666
  Batch 1128 Loss: 4.6973
  Batch 1132 Loss: 4.9135
  Batch 1136 Loss: 4.7537
  Batch 1140 Loss: 4.0412
  Batch 1144 Loss: 4.9990
  Batch 1148 Loss: 4.5928
  Batch 1152 Loss: 4.8759
  Batch 1156 Loss: 4.2071
  Batch 1160 Loss: 4.9549
  Batch 1164 Loss: 4.3257
  Batch 1168 Loss: 4.0842
  Batch 1172 Loss: 4.1798
  Batch 1176 Loss: 3.8496
  Batch 1180 Loss: 3.9995
  Batch 1184 Loss: 4.2332
  Batch 1188 Loss: 4.0847
  Batch 1192 Loss: 4.7106
  Batch 1196 Loss: 4.1322
  Batch 1200 Loss: 4.5789
  Batch 1204 Loss: 4.5172
  Batch 1208 Loss: 4.1737
  Batch 1212 Loss: 4.1775
  Batch 1216 Loss: 4.3994
  Batch 1220 Loss: 4.2582
  Batch 1224 Loss: 4.3527
  Batch 1228 Loss: 4.6506
  Batch 1232 Loss: 4.6392
  Batch 1236 Loss: 4.0157
  Batch 1240 Loss: 4.3123
  Batch 1244 Loss: 4.9040
  Batch 1248 Loss: 4.1544
  Batch 1252 Loss: 4.4008
  Batch 1256 Loss: 4.5256
  Batch 1260 Loss: 4.7516
  Batch 1264 Loss: 4.8633
  Batch 1268 Loss: 4.2411
  Batch 1272 Loss: 4.7456
  Batch 1276 Loss: 4.2430
  Batch 1280 Loss: 4.1561
  Batch 1284 Loss: 4.8659
  Batch 1288 Loss: 4.9960
  Batch 1292 Loss: 4.3482
  Batch 1296 Loss: 4.7771
  Batch 1300 Loss: 4.1286
  Batch 1304 Loss: 3.8776
  Batch 1308 Loss: 4.1063
  Batch 1312 Loss: 4.2028
  Batch 1316 Loss: 4.4759
  Batch 1320 Loss: 3.9544
  Batch 1324 Loss: 4.2836
  Batch 1328 Loss: 4.5797
  Batch 1332 Loss: 3.8892
  Batch 1336 Loss: 3.9969
  Batch 1340 Loss: 4.1472
  Batch 1344 Loss: 4.0299
  Batch 1348 Loss: 4.6490
  Batch 1352 Loss: 4.2983
  Batch 1356 Loss: 4.5526
  Batch 1360 Loss: 4.9189
  Batch 1364 Loss: 4.5227
  Batch 1368 Loss: 4.0398
  Batch 1372 Loss: 4.2775
  Batch 1376 Loss: 4.4739
  Batch 1380 Loss: 4.0785
  Batch 1384 Loss: 4.3297
  Batch 1388 Loss: 3.7246
  Batch 1392 Loss: 3.8793
  Batch 1396 Loss: 4.7123
  Batch 1400 Loss: 4.5802
  Batch 1404 Loss: 3.6114
  Batch 1408 Loss: 4.5227
  Batch 1412 Loss: 4.2661
  Batch 1416 Loss: 4.0811
  Batch 1420 Loss: 4.2420
  Batch 1424 Loss: 3.8241
  Batch 1428 Loss: 3.8098
  Batch 1432 Loss: 4.2713
  Batch 1436 Loss: 4.1509
  Batch 1440 Loss: 4.0280
  Batch 1444 Loss: 5.5068
  Batch 1448 Loss: 4.1288
  Batch 1452 Loss: 4.8424
  Batch 1456 Loss: 4.2920
  Batch 1460 Loss: 3.6775
  Batch 1464 Loss: 4.5025
  Batch 1468 Loss: 3.9900
  Batch 1472 Loss: 4.5675
  Batch 1476 Loss: 4.1899
  Batch 1480 Loss: 4.8854
  Batch 1484 Loss: 4.5450
  Batch 1488 Loss: 4.2016
  Batch 1492 Loss: 3.5841
  Batch 1496 Loss: 4.2395
  Batch 1500 Loss: 4.0287
  Batch 1504 Loss: 3.7135
  Batch 1508 Loss: 4.2568
  Batch 1512 Loss: 4.1448
  Batch 1516 Loss: 4.6382
  Batch 1520 Loss: 3.8965
  Batch 1524 Loss: 3.9707
  Batch 1528 Loss: 4.4064
  Batch 1532 Loss: 4.6356
  Batch 1536 Loss: 3.8113
  Batch 1540 Loss: 4.1050
  Batch 1544 Loss: 4.2779
  Batch 1548 Loss: 4.4296
  Batch 1552 Loss: 4.3926
  Batch 1556 Loss: 3.9268
  Batch 1560 Loss: 3.7789
  Batch 1564 Loss: 3.9144
  Batch 1568 Loss: 3.9766
  Batch 1572 Loss: 4.4551
  Batch 1576 Loss: 3.6298
  Batch 1580 Loss: 4.0214
  Batch 1584 Loss: 3.8783
  Batch 1588 Loss: 4.6343
  Batch 1592 Loss: 3.9024
  Batch 1596 Loss: 3.9984
  Batch 1600 Loss: 4.0297
  Batch 1604 Loss: 3.8571
  Batch 1608 Loss: 3.6722
  Batch 1612 Loss: 4.1402
  Batch 1616 Loss: 4.3465
  Batch 1620 Loss: 4.3884
  Batch 1624 Loss: 4.6158
  Batch 1628 Loss: 3.9578
  Batch 1632 Loss: 3.9689
  Batch 1636 Loss: 3.7876
  Batch 1640 Loss: 4.4988
  Batch 1644 Loss: 4.3098
  Batch 1648 Loss: 4.3277
  Batch 1652 Loss: 4.7719
  Batch 1656 Loss: 3.8247
  Batch 1660 Loss: 3.9915
  Batch 1664 Loss: 3.9461
  Batch 1668 Loss: 4.5934
  Batch 1672 Loss: 3.9248
  Batch 1676 Loss: 4.1823
  Batch 1680 Loss: 3.6368
  Batch 1684 Loss: 3.3317
  Batch 1688 Loss: 3.4795
  Batch 1692 Loss: 4.4925
  Batch 1696 Loss: 3.6322
  Batch 1700 Loss: 4.1649
  Batch 1704 Loss: 3.6306
  Batch 1708 Loss: 3.6762
  Batch 1712 Loss: 4.4090
  Batch 1716 Loss: 3.5503
  Batch 1720 Loss: 3.0405
  Batch 1724 Loss: 3.8543
  Batch 1728 Loss: 3.4782
  Batch 1732 Loss: 4.3627
  Batch 1736 Loss: 4.9865
  Batch 1740 Loss: 3.8078
  Batch 1744 Loss: 3.7691
  Batch 1748 Loss: 3.7955
  Batch 1752 Loss: 3.2289
  Batch 1756 Loss: 3.8099
  Batch 1760 Loss: 4.0517
  Batch 1764 Loss: 3.3378
  Batch 1768 Loss: 3.6474
  Batch 1772 Loss: 3.4180
  Batch 1776 Loss: 4.2207
  Batch 1780 Loss: 3.9344
  Batch 1784 Loss: 3.5996
  Batch 1788 Loss: 4.2412
  Batch 1792 Loss: 4.2568
  Batch 1796 Loss: 3.8079
  Batch 1800 Loss: 4.3535
  Batch 1804 Loss: 3.6857
  Batch 1808 Loss: 4.2436
  Batch 1812 Loss: 4.0338
  Batch 1816 Loss: 4.0059
  Batch 1820 Loss: 4.0543
  Batch 1824 Loss: 3.7459
  Batch 1828 Loss: 3.3827
  Batch 1832 Loss: 3.6660
  Batch 1836 Loss: 3.6905
  Batch 1840 Loss: 3.5595
  Batch 1844 Loss: 3.2194
  Batch 1848 Loss: 3.9730
  Batch 1852 Loss: 4.8177
  Batch 1856 Loss: 3.9907
  Batch 1860 Loss: 4.0631
  Batch 1864 Loss: 3.8496
  Batch 1868 Loss: 4.0765
  Batch 1872 Loss: 3.2588
  Batch 1876 Loss: 3.8395
  Batch 1880 Loss: 4.0855
  Batch 1884 Loss: 3.5388
  Batch 1888 Loss: 3.3980
  Batch 1892 Loss: 3.5575
  Batch 1896 Loss: 4.0439
  Batch 1900 Loss: 3.7793
  Batch 1904 Loss: 4.1333
  Batch 1908 Loss: 4.2462
  Batch 1912 Loss: 3.5766
  Batch 1916 Loss: 3.8085
  Batch 1920 Loss: 4.0716
  Batch 1924 Loss: 3.9434
  Batch 1928 Loss: 3.8213
  Batch 1932 Loss: 3.6863
  Batch 1936 Loss: 3.8332
  Batch 1940 Loss: 3.4401
  Batch 1944 Loss: 3.6344
  Batch 1948 Loss: 3.5397
  Batch 1952 Loss: 4.1980
  Batch 1956 Loss: 4.2441
  Batch 1960 Loss: 3.6824
  Batch 1964 Loss: 3.6820
  Batch 1968 Loss: 3.9760
  Batch 1972 Loss: 3.7951
  Batch 1976 Loss: 3.3774
  Batch 1980 Loss: 3.2101
  Batch 1984 Loss: 4.4440
  Batch 1988 Loss: 3.7720
  Batch 1992 Loss: 4.1191
  Batch 1996 Loss: 4.0508
  Batch 2000 Loss: 3.3743
  Batch 2004 Loss: 3.6075
  Batch 2008 Loss: 3.8158
  Batch 2012 Loss: 3.7186
  Batch 2016 Loss: 3.4008
  Batch 2020 Loss: 3.8917
  Batch 2024 Loss: 3.8538
  Batch 2028 Loss: 3.8531
  Batch 2032 Loss: 3.6394
  Batch 2036 Loss: 4.3510
  Batch 2040 Loss: 3.9536
  Batch 2044 Loss: 3.7628
  Batch 2048 Loss: 4.1219
  Batch 2052 Loss: 3.6687
  Batch 2056 Loss: 3.1963
  Batch 2060 Loss: 3.6839
  Batch 2064 Loss: 3.3463
  Batch 2068 Loss: 3.4026
  Batch 2072 Loss: 3.3713
  Batch 2076 Loss: 3.7832
  Batch 2080 Loss: 3.5354
  Batch 2084 Loss: 3.8965
  Batch 2088 Loss: 3.3708
  Batch 2092 Loss: 4.2368
  Batch 2096 Loss: 3.3321
  Batch 2100 Loss: 3.4992
  Batch 2104 Loss: 4.3703
  Batch 2108 Loss: 4.0315
  Batch 2112 Loss: 4.1576
  Batch 2116 Loss: 3.2268
  Batch 2120 Loss: 3.1006
  Batch 2124 Loss: 3.8748
  Batch 2128 Loss: 3.6931
  Batch 2132 Loss: 3.5964
  Batch 2136 Loss: 3.7194
  Batch 2140 Loss: 3.2600
  Batch 2144 Loss: 3.5777
  Batch 2148 Loss: 4.1432
  Batch 2152 Loss: 3.8669
  Batch 2156 Loss: 3.7935
  Batch 2160 Loss: 3.8264
  Batch 2164 Loss: 2.7455
  Batch 2168 Loss: 4.1140
  Batch 2172 Loss: 3.4183
  Batch 2176 Loss: 3.3976
  Batch 2180 Loss: 3.2324
  Batch 2184 Loss: 2.8226
  Batch 2188 Loss: 3.8150
  Batch 2192 Loss: 3.8814
  Batch 2196 Loss: 3.6897
  Batch 2200 Loss: 3.9233
  Batch 2204 Loss: 3.7002
  Batch 2208 Loss: 3.4744
  Batch 2212 Loss: 3.9136
  Batch 2216 Loss: 4.1834
  Batch 2220 Loss: 3.8652
  Batch 2224 Loss: 3.1816
  Batch 2228 Loss: 3.3171
  Batch 2232 Loss: 3.5090
  Batch 2236 Loss: 4.2970
  Batch 2240 Loss: 3.5382
  Batch 2244 Loss: 3.5872
  Batch 2248 Loss: 3.4737
  Batch 2252 Loss: 3.7741
  Batch 2256 Loss: 4.8190
  Batch 2260 Loss: 4.8107
  Batch 2264 Loss: 3.2290
  Batch 2268 Loss: 3.5184
  Batch 2272 Loss: 3.3851
  Batch 2276 Loss: 4.5504
  Batch 2280 Loss: 3.3449
  Batch 2284 Loss: 3.1884
  Batch 2288 Loss: 3.5770
  Batch 2292 Loss: 3.7986
  Batch 2296 Loss: 4.8139
  Batch 2300 Loss: 3.4731
  Batch 2304 Loss: 3.6993
  Batch 2308 Loss: 3.5134
  Batch 2312 Loss: 3.9637
  Batch 2316 Loss: 3.8105
  Batch 2320 Loss: 3.2741
  Batch 2324 Loss: 4.2083
  Batch 2328 Loss: 3.8328
  Batch 2332 Loss: 3.3039
  Batch 2336 Loss: 3.7531
  Batch 2340 Loss: 3.7078
  Batch 2344 Loss: 3.8142
  Batch 2348 Loss: 4.3934
  Batch 2352 Loss: 3.1177
  Batch 2356 Loss: 3.2643
  Batch 2360 Loss: 3.4586
  Batch 2364 Loss: 3.6036
  Batch 2368 Loss: 3.3960
  Batch 2372 Loss: 3.5170
  Batch 2376 Loss: 3.8102
  Batch 2380 Loss: 3.1440
  Batch 2384 Loss: 4.2017
  Batch 2388 Loss: 3.8320
  Batch 2392 Loss: 3.6474
  Batch 2396 Loss: 4.2190
  Batch 2400 Loss: 3.6539
  Batch 2404 Loss: 3.9861
  Batch 2408 Loss: 3.6211
  Batch 2412 Loss: 3.8418
  Batch 2416 Loss: 3.2478
  Batch 2420 Loss: 3.6523
  Batch 2424 Loss: 3.6001
  Batch 2428 Loss: 4.1817
  Batch 2432 Loss: 4.4612
  Batch 2436 Loss: 3.4678
  Batch 2440 Loss: 3.3086
  Batch 2444 Loss: 3.8213
  Batch 2448 Loss: 3.0348
  Batch 2452 Loss: 3.6935
  Batch 2456 Loss: 3.4609
  Batch 2460 Loss: 3.6910
  Batch 2464 Loss: 4.0219
  Batch 2468 Loss: 3.5262
  Batch 2472 Loss: 3.5753
  Batch 2476 Loss: 3.5023
  Batch 2480 Loss: 3.9502
  Batch 2484 Loss: 4.2079
  Batch 2488 Loss: 3.6938
  Batch 2492 Loss: 4.3330
  Batch 2496 Loss: 3.7101
  Batch 2500 Loss: 4.0269
  Batch 2504 Loss: 3.6801
  Batch 2508 Loss: 3.4481
  Batch 2512 Loss: 3.7767
  Batch 2516 Loss: 3.5716
  Batch 2520 Loss: 3.6706
  Batch 2524 Loss: 3.4787
  Batch 2528 Loss: 3.2537
  Batch 2532 Loss: 3.1927
  Batch 2536 Loss: 4.6273
  Batch 2540 Loss: 3.5964
  Batch 2544 Loss: 3.9498
  Batch 2548 Loss: 3.5908
  Batch 2552 Loss: 3.8913
  Batch 2556 Loss: 3.6452
  Batch 2560 Loss: 3.8489
  Batch 2564 Loss: 3.5892
  Batch 2568 Loss: 3.4706
  Batch 2572 Loss: 3.4824
  Batch 2576 Loss: 3.4876
  Batch 2580 Loss: 3.7015
  Batch 2584 Loss: 3.8748
  Batch 2588 Loss: 4.1390
  Batch 2592 Loss: 4.5085
  Batch 2596 Loss: 3.6689
  Batch 2600 Loss: 3.4259
  Batch 2604 Loss: 3.5061
  Batch 2608 Loss: 3.8507
  Batch 2612 Loss: 3.8878
  Batch 2616 Loss: 4.1118
  Batch 2620 Loss: 4.5140
  Batch 2624 Loss: 3.9793
  Batch 2628 Loss: 3.3508
  Batch 2632 Loss: 3.6461
  Batch 2636 Loss: 3.0215
  Batch 2640 Loss: 3.8688
  Batch 2644 Loss: 3.8925
  Batch 2648 Loss: 3.1139
  Batch 2652 Loss: 3.1954
  Batch 2656 Loss: 4.0007
  Batch 2660 Loss: 3.1435
  Batch 2664 Loss: 3.8396
  Batch 2668 Loss: 4.0070
  Batch 2672 Loss: 4.1663
  Batch 2676 Loss: 3.7572
  Batch 2680 Loss: 3.6417
  Batch 2684 Loss: 3.3204
  Batch 2688 Loss: 3.8300
  Batch 2692 Loss: 4.4571
  Batch 2696 Loss: 3.6734
  Batch 2700 Loss: 3.1885
  Batch 2704 Loss: 3.9062
  Batch 2708 Loss: 3.5683
  Batch 2712 Loss: 4.3838
  Batch 2716 Loss: 4.0721
  Batch 2720 Loss: 3.3508
  Batch 2724 Loss: 4.0851
  Batch 2728 Loss: 2.8192
  Batch 2732 Loss: 3.5259
  Batch 2736 Loss: 3.2098
  Batch 2740 Loss: 3.9591
  Batch 2744 Loss: 2.9902
  Batch 2748 Loss: 3.5454
  Batch 2752 Loss: 3.3661
  Batch 2756 Loss: 3.9811
  Batch 2760 Loss: 3.4002
  Batch 2764 Loss: 3.3719
  Batch 2768 Loss: 3.4386
  Batch 2772 Loss: 3.7804
  Batch 2776 Loss: 3.9782
  Batch 2780 Loss: 3.5765
  Batch 2784 Loss: 3.5302
  Batch 2788 Loss: 3.5882
  Batch 2792 Loss: 2.9332
  Batch 2796 Loss: 3.4995
  Batch 2800 Loss: 3.5158
  Batch 2804 Loss: 3.3259
  Batch 2808 Loss: 3.4084
  Batch 2812 Loss: 3.9437
  Batch 2816 Loss: 3.5070
  Batch 2820 Loss: 3.6356
  Batch 2824 Loss: 3.5219
  Batch 2828 Loss: 3.5537
  Batch 2832 Loss: 3.4616
  Batch 2836 Loss: 3.7150
  Batch 2840 Loss: 3.5430
  Batch 2844 Loss: 4.2664
  Batch 2848 Loss: 3.2407
  Batch 2852 Loss: 3.3297
  Batch 2856 Loss: 3.4510
  Batch 2860 Loss: 3.3700
  Batch 2864 Loss: 3.5481
  Batch 2868 Loss: 3.4886
  Batch 2872 Loss: 3.3254
  Batch 2876 Loss: 4.0812
  Batch 2880 Loss: 3.5483
  Batch 2884 Loss: 3.7784
  Batch 2888 Loss: 3.4922
  Batch 2892 Loss: 3.5793
  Batch 2896 Loss: 3.2754
  Batch 2900 Loss: 3.4397
  Batch 2904 Loss: 3.3103
  Batch 2908 Loss: 3.8836
  Batch 2912 Loss: 3.6623
  Batch 2916 Loss: 3.6301
  Batch 2920 Loss: 3.2132
  Batch 2924 Loss: 3.5195
  Batch 2928 Loss: 3.7038
  Batch 2932 Loss: 3.9809
  Batch 2936 Loss: 3.3027
  Batch 2940 Loss: 3.4526
  Batch 2944 Loss: 3.9136
  Batch 2948 Loss: 3.9134
  Batch 2952 Loss: 3.3184
  Batch 2956 Loss: 4.0827
  Batch 2960 Loss: 3.5638
  Batch 2964 Loss: 3.1024
  Batch 2968 Loss: 3.5033
  Batch 2972 Loss: 3.7019
  Batch 2976 Loss: 4.0729
  Batch 2980 Loss: 3.5574
  Batch 2984 Loss: 3.0212
  Batch 2988 Loss: 3.7324
  Batch 2992 Loss: 3.6686
  Batch 2996 Loss: 3.6281
  Batch 3000 Loss: 3.8847
  Batch 3004 Loss: 3.5695
  Batch 3008 Loss: 3.7757
  Batch 3012 Loss: 3.8392
  Batch 3016 Loss: 3.0929
  Batch 3020 Loss: 3.3233
  Batch 3024 Loss: 3.4174
  Batch 3028 Loss: 3.5953
  Batch 3032 Loss: 4.2455
  Batch 3036 Loss: 3.6895
  Batch 3040 Loss: 3.5284
  Batch 3044 Loss: 3.1946
  Batch 3048 Loss: 3.3456
  Batch 3052 Loss: 3.5912
  Batch 3056 Loss: 3.0538
  Batch 3060 Loss: 3.7235
  Batch 3064 Loss: 3.1679
  Batch 3068 Loss: 3.6308
  Batch 3072 Loss: 3.2933
  Batch 3076 Loss: 3.4278
  Batch 3080 Loss: 3.6844
  Batch 3084 Loss: 3.0559
  Batch 3088 Loss: 3.6452
  Batch 3092 Loss: 3.1996
  Batch 3096 Loss: 4.0784
  Batch 3100 Loss: 4.2747
  Batch 3104 Loss: 3.3717
  Batch 3108 Loss: 3.9666
  Batch 3112 Loss: 3.0947
  Batch 3116 Loss: 3.6147
  Batch 3120 Loss: 4.3670
  Batch 3124 Loss: 3.3516
  Batch 3128 Loss: 3.5733
  Batch 3132 Loss: 3.4344
  Batch 3136 Loss: 3.3370
  Batch 3140 Loss: 3.8358
  Batch 3144 Loss: 3.3748
  Batch 3148 Loss: 3.5563
  Batch 3152 Loss: 3.6434
  Batch 3156 Loss: 3.4551
  Batch 3160 Loss: 3.6953
  Batch 3164 Loss: 3.6990
  Batch 3168 Loss: 3.9183
  Batch 3172 Loss: 3.1278
  Batch 3176 Loss: 3.4961
  Batch 3180 Loss: 3.5894
  Batch 3184 Loss: 3.2796
  Batch 3188 Loss: 4.2262
  Batch 3192 Loss: 4.1313
  Batch 3196 Loss: 3.1755
  Batch 3200 Loss: 3.2242
  Batch 3204 Loss: 3.7206
  Batch 3208 Loss: 3.3749
  Batch 3212 Loss: 3.3032
  Batch 3216 Loss: 3.2603
  Batch 3220 Loss: 3.7230
  Batch 3224 Loss: 3.3622
  Batch 3228 Loss: 3.1512
  Batch 3232 Loss: 3.7021
  Batch 3236 Loss: 3.0643
  Batch 3240 Loss: 3.7552
  Batch 3244 Loss: 3.1617
  Batch 3248 Loss: 3.6531
  Batch 3252 Loss: 3.8903
  Batch 3256 Loss: 3.1631
  Batch 3260 Loss: 3.4659
  Batch 3264 Loss: 2.9694
  Batch 3268 Loss: 2.7514
  Batch 3272 Loss: 3.5984
  Batch 3276 Loss: 4.0212
  Batch 3280 Loss: 3.7369
  Batch 3284 Loss: 3.2920
  Batch 3288 Loss: 3.3255
  Batch 3292 Loss: 3.4416
  Batch 3296 Loss: 3.3214
  Batch 3300 Loss: 3.4602
  Batch 3304 Loss: 3.5875
  Batch 3308 Loss: 2.8033
  Batch 3312 Loss: 4.3921
  Batch 3316 Loss: 3.8438
  Batch 3320 Loss: 3.5217
  Batch 3324 Loss: 3.8066
  Batch 3328 Loss: 2.9056
  Batch 3332 Loss: 3.8940
  Batch 3336 Loss: 3.3634
  Batch 3340 Loss: 2.9684
  Batch 3344 Loss: 3.8756
  Batch 3348 Loss: 3.4734
  Batch 3352 Loss: 3.5109
  Batch 3356 Loss: 4.6220
  Batch 3360 Loss: 3.9509
  Batch 3364 Loss: 3.4919
  Batch 3368 Loss: 3.3387
  Batch 3372 Loss: 3.6682
  Batch 3376 Loss: 4.0810
  Batch 3380 Loss: 3.9653
  Batch 3384 Loss: 3.7727
  Batch 3388 Loss: 3.5995
  Batch 3392 Loss: 3.2648
  Batch 3396 Loss: 3.7790
  Batch 3400 Loss: 3.1056
  Batch 3404 Loss: 3.6288
  Batch 3408 Loss: 3.0455
  Batch 3412 Loss: 3.8801
  Batch 3416 Loss: 3.5176
  Batch 3420 Loss: 4.0221
  Batch 3424 Loss: 3.6486
  Batch 3428 Loss: 3.9141
  Batch 3432 Loss: 3.3432
  Batch 3436 Loss: 3.4220
  Batch 3440 Loss: 3.8411
  Batch 3444 Loss: 3.0732
  Batch 3448 Loss: 3.8514
  Batch 3452 Loss: 3.5815
  Batch 3456 Loss: 3.0918
  Batch 3460 Loss: 3.1127
  Batch 3464 Loss: 3.8688
  Batch 3468 Loss: 3.4197
  Batch 3472 Loss: 3.6127
  Batch 3476 Loss: 3.6355
  Batch 3480 Loss: 3.7137
  Batch 3484 Loss: 3.5886
  Batch 3488 Loss: 3.2289
  Batch 3492 Loss: 2.6424
  Batch 3496 Loss: 3.6978
  Batch 3500 Loss: 3.5355
  Batch 3504 Loss: 3.5786
  Batch 3508 Loss: 3.3949
  Batch 3512 Loss: 3.5778
  Batch 3516 Loss: 3.8987
  Batch 3520 Loss: 3.2141
  Batch 3524 Loss: 3.5083
  Batch 3528 Loss: 3.2635
  Batch 3532 Loss: 3.5035
  Batch 3536 Loss: 3.1472
  Batch 3540 Loss: 3.4837
  Batch 3544 Loss: 4.1019
  Batch 3548 Loss: 3.1079
  Batch 3552 Loss: 3.9538
  Batch 3556 Loss: 3.5162
  Batch 3560 Loss: 4.0876
  Batch 3564 Loss: 3.0777
  Batch 3568 Loss: 3.4582
  Batch 3572 Loss: 3.4841
  Batch 3576 Loss: 3.3679
  Batch 3580 Loss: 3.3118
  Batch 3584 Loss: 3.9796
  Batch 3588 Loss: 3.6052
  Batch 3592 Loss: 3.1819
  Batch 3596 Loss: 2.7813
  Batch 3600 Loss: 3.4501
  Batch 3604 Loss: 3.3937
  Batch 3608 Loss: 3.7290
  Batch 3612 Loss: 3.3653
  Batch 3616 Loss: 3.7738
  Batch 3620 Loss: 3.2115
  Batch 3624 Loss: 3.3415
  Batch 3628 Loss: 3.4983
  Batch 3632 Loss: 3.2314
  Batch 3636 Loss: 3.6576
  Batch 3640 Loss: 4.3046
  Batch 3644 Loss: 3.6402
  Batch 3648 Loss: 3.1370
  Batch 3652 Loss: 3.1484
  Batch 3656 Loss: 3.7910
  Batch 3660 Loss: 3.1608
  Batch 3664 Loss: 3.2136
  Batch 3668 Loss: 3.5970
  Batch 3672 Loss: 3.6735
  Batch 3676 Loss: 4.1702
  Batch 3680 Loss: 3.3617
  Batch 3684 Loss: 3.4890
  Batch 3688 Loss: 3.8224
  Batch 3692 Loss: 3.3903
  Batch 3696 Loss: 3.3997
  Batch 3700 Loss: 3.9704
  Batch 3704 Loss: 4.0111
  Batch 3708 Loss: 4.5352
  Batch 3712 Loss: 3.2991
  Batch 3716 Loss: 3.1854
  Batch 3720 Loss: 3.5085
  Batch 3724 Loss: 3.6668
  Batch 3728 Loss: 3.5228
  Batch 3732 Loss: 3.3612
  Batch 3736 Loss: 4.5845
  Batch 3740 Loss: 3.1762
  Batch 3744 Loss: 3.6970
  Batch 3748 Loss: 3.4391
  Batch 3752 Loss: 3.5523
  Batch 3756 Loss: 4.4248
  Batch 3760 Loss: 2.9261
  Batch 3764 Loss: 3.1527
  Batch 3768 Loss: 3.3775
  Batch 3772 Loss: 3.3676
  Batch 3776 Loss: 4.3190
  Batch 3780 Loss: 3.0668
  Batch 3784 Loss: 3.4446
  Batch 3788 Loss: 3.6145
  Batch 3792 Loss: 3.3333
  Batch 3796 Loss: 3.8875
  Batch 3800 Loss: 3.3188
  Batch 3804 Loss: 3.6324
  Batch 3808 Loss: 3.4385
  Batch 3812 Loss: 3.7645
  Batch 3816 Loss: 2.9946
  Batch 3820 Loss: 3.5656
  Batch 3824 Loss: 3.6877
  Batch 3828 Loss: 3.5882
  Batch 3832 Loss: 3.4210
  Batch 3836 Loss: 3.7402
  Batch 3840 Loss: 3.7987
  Batch 3844 Loss: 3.5801
  Batch 3848 Loss: 3.3763
  Batch 3852 Loss: 3.7638
  Batch 3856 Loss: 3.1557
  Batch 3860 Loss: 3.5475
  Batch 3864 Loss: 2.8753
  Batch 3868 Loss: 4.1102
  Batch 3872 Loss: 3.7505
  Batch 3876 Loss: 3.5630
  Batch 3880 Loss: 3.1663
  Batch 3884 Loss: 3.9904
  Batch 3888 Loss: 4.4204
  Batch 3892 Loss: 3.8513
  Batch 3896 Loss: 2.9496
  Batch 3900 Loss: 3.8934
  Batch 3904 Loss: 3.1219
  Batch 3908 Loss: 3.5010
  Batch 3912 Loss: 3.1509
  Batch 3916 Loss: 3.6798
  Batch 3920 Loss: 3.3741
  Batch 3924 Loss: 3.3015
  Batch 3928 Loss: 4.3063
  Batch 3932 Loss: 3.4245
  Batch 3936 Loss: 3.6992
  Batch 3940 Loss: 3.0206
  Batch 3944 Loss: 3.9411
  Batch 3948 Loss: 2.8632
  Batch 3952 Loss: 3.5074
  Batch 3956 Loss: 3.2663
  Batch 3960 Loss: 3.5046
  Batch 3964 Loss: 3.4035
  Batch 3968 Loss: 3.3946
  Batch 3972 Loss: 3.7380
  Batch 3976 Loss: 3.4233
  Batch 3980 Loss: 5.1070
  Batch 3984 Loss: 3.8380
  Batch 3988 Loss: 3.2042
  Batch 3992 Loss: 3.4074
  Batch 3996 Loss: 3.2055
  Batch 4000 Loss: 3.2193
  Batch 4004 Loss: 3.7161
  Batch 4008 Loss: 3.8351
  Batch 4012 Loss: 2.9857
  Batch 4016 Loss: 3.8218
  Batch 4020 Loss: 3.7537
  Batch 4024 Loss: 3.7294
  Batch 4028 Loss: 3.6277
  Batch 4032 Loss: 2.9220
  Batch 4036 Loss: 3.5587
  Batch 4040 Loss: 3.5073
  Batch 4044 Loss: 3.6238
  Batch 4048 Loss: 3.4802
  Batch 4052 Loss: 3.2792
  Batch 4056 Loss: 3.2531
  Batch 4060 Loss: 3.3575
  Batch 4064 Loss: 3.7716
  Batch 4068 Loss: 3.5512
  Batch 4072 Loss: 4.2258
  Batch 4076 Loss: 3.5012
  Batch 4080 Loss: 3.2801
  Batch 4084 Loss: 3.4621
  Batch 4088 Loss: 3.7149
  Batch 4092 Loss: 3.3517
  Batch 4096 Loss: 3.1600
  Batch 4100 Loss: 3.1959
  Batch 4104 Loss: 3.3455
  Batch 4108 Loss: 3.8650
  Batch 4112 Loss: 2.9691
  Batch 4116 Loss: 3.2512
  Batch 4120 Loss: 3.5669
  Batch 4124 Loss: 3.7126
  Batch 4128 Loss: 3.1873
  Batch 4132 Loss: 2.9819
  Batch 4136 Loss: 3.1785
  Batch 4140 Loss: 3.5072
  Batch 4144 Loss: 3.3033
  Batch 4148 Loss: 3.3314
  Batch 4152 Loss: 3.1009
  Batch 4156 Loss: 3.9134
  Batch 4160 Loss: 3.4929
  Batch 4164 Loss: 3.1072
  Batch 4168 Loss: 3.0660
  Batch 4172 Loss: 3.5866
  Batch 4176 Loss: 3.7263
  Batch 4180 Loss: 3.4761
  Batch 4184 Loss: 3.2065
  Batch 4188 Loss: 2.8680
  Batch 4192 Loss: 3.8179
  Batch 4196 Loss: 3.5148
  Batch 4200 Loss: 3.3181
  Batch 4204 Loss: 3.7643
  Batch 4208 Loss: 3.4229
  Batch 4212 Loss: 2.7489
  Batch 4216 Loss: 2.9382
  Batch 4220 Loss: 3.5849
  Batch 4224 Loss: 3.3598
  Batch 4228 Loss: 2.9354
  Batch 4232 Loss: 3.4667
  Batch 4236 Loss: 3.2794
  Batch 4240 Loss: 3.4579
  Batch 4244 Loss: 3.6576
  Batch 4248 Loss: 3.6208
  Batch 4252 Loss: 3.2159
  Batch 4256 Loss: 3.8492
  Batch 4260 Loss: 3.5566
  Batch 4264 Loss: 3.6456
  Batch 4268 Loss: 4.0440
  Batch 4272 Loss: 3.3777
  Batch 4276 Loss: 3.3988
  Batch 4280 Loss: 3.0064
  Batch 4284 Loss: 3.2901
  Batch 4288 Loss: 2.9533
  Batch 4292 Loss: 3.5073
  Batch 4296 Loss: 3.4387
  Batch 4300 Loss: 3.9283
  Batch 4304 Loss: 2.9341
  Batch 4308 Loss: 3.4639
  Batch 4312 Loss: 3.5374
  Batch 4316 Loss: 3.8965
  Batch 4320 Loss: 3.3201
  Batch 4324 Loss: 3.9434
  Batch 4328 Loss: 3.9503
  Batch 4332 Loss: 3.8221
  Batch 4336 Loss: 3.2857
  Batch 4340 Loss: 2.8376
  Batch 4344 Loss: 3.0903
  Batch 4348 Loss: 3.6630
  Batch 4352 Loss: 3.2057
  Batch 4356 Loss: 3.6042
  Batch 4360 Loss: 3.2074
  Batch 4364 Loss: 3.5114
  Batch 4368 Loss: 3.3538
  Batch 4372 Loss: 3.3496
  Batch 4376 Loss: 3.2299
  Batch 4380 Loss: 3.5464
  Batch 4384 Loss: 3.6569
  Batch 4388 Loss: 3.4991
  Batch 4392 Loss: 3.7938
  Batch 4396 Loss: 3.5876
  Batch 4400 Loss: 3.1845
  Batch 4404 Loss: 3.7492
  Batch 4408 Loss: 3.2590
  Batch 4412 Loss: 3.2915
  Batch 4416 Loss: 3.1611
  Batch 4420 Loss: 4.2405
  Batch 4424 Loss: 3.5316
  Batch 4428 Loss: 3.5316
  Batch 4432 Loss: 4.5477
  Batch 4436 Loss: 3.3625
  Batch 4440 Loss: 4.0362
  Batch 4444 Loss: 3.3612
  Batch 4448 Loss: 3.3508
  Batch 4452 Loss: 2.8091
  Batch 4456 Loss: 3.8580
  Batch 4460 Loss: 3.2408
  Batch 4464 Loss: 3.4669
  Batch 4468 Loss: 4.1921
  Batch 4472 Loss: 4.0988
  Batch 4476 Loss: 3.9160
  Batch 4480 Loss: 3.4462
  Batch 4484 Loss: 3.4786
  Batch 4488 Loss: 2.9819
  Batch 4492 Loss: 3.2714
  Batch 4496 Loss: 3.0793
  Batch 4500 Loss: 3.4613
  Batch 4504 Loss: 3.5831
  Batch 4508 Loss: 3.5474
  Batch 4512 Loss: 2.9455
  Batch 4516 Loss: 3.2802
  Batch 4520 Loss: 3.5111
  Batch 4524 Loss: 3.2519
  Batch 4528 Loss: 3.5977
  Batch 4532 Loss: 3.4827
  Batch 4536 Loss: 3.7872
  Batch 4540 Loss: 3.5678
  Batch 4544 Loss: 3.4537
  Batch 4548 Loss: 3.5974
  Batch 4552 Loss: 3.3110
  Batch 4556 Loss: 3.7358
  Batch 4560 Loss: 3.6098
  Batch 4564 Loss: 3.2207
  Batch 4568 Loss: 3.2308
  Batch 4572 Loss: 3.8114
  Batch 4576 Loss: 3.6804
  Batch 4580 Loss: 3.4072
  Batch 4584 Loss: 3.2938
  Batch 4588 Loss: 3.2024
  Batch 4592 Loss: 3.4898
  Batch 4596 Loss: 3.1883
  Batch 4600 Loss: 3.3055
  Batch 4604 Loss: 3.1688
  Batch 4608 Loss: 3.1370
  Batch 4612 Loss: 3.7949
  Batch 4616 Loss: 3.4574
  Batch 4620 Loss: 3.7568
  Batch 4624 Loss: 3.1218
  Batch 4628 Loss: 3.4466
  Batch 4632 Loss: 3.2519
  Batch 4636 Loss: 3.0667
  Batch 4640 Loss: 3.6131
  Batch 4644 Loss: 3.3290
  Batch 4648 Loss: 4.0922
  Batch 4652 Loss: 3.7214
  Batch 4656 Loss: 3.2401
  Batch 4660 Loss: 3.2790
  Batch 4664 Loss: 3.9226
  Batch 4668 Loss: 3.1333
  Batch 4672 Loss: 2.8044
  Batch 4676 Loss: 3.2464
  Batch 4680 Loss: 3.5008
  Batch 4684 Loss: 2.7091
  Batch 4688 Loss: 3.2881
  Batch 4692 Loss: 3.4465
  Batch 4696 Loss: 3.6322
  Batch 4700 Loss: 2.9659
  Batch 4704 Loss: 3.4677
  Batch 4708 Loss: 3.2614
  Batch 4712 Loss: 2.7484
  Batch 4716 Loss: 3.4381
  Batch 4720 Loss: 3.5139
  Batch 4724 Loss: 3.4990
  Batch 4728 Loss: 3.3590
  Batch 4732 Loss: 3.8016
  Batch 4736 Loss: 3.4518
  Batch 4740 Loss: 2.8143
  Batch 4744 Loss: 2.9342
  Batch 4748 Loss: 3.5865
  Batch 4752 Loss: 3.8922
  Batch 4756 Loss: 3.6739
  Batch 4760 Loss: 3.4236
  Batch 4764 Loss: 3.0881
  Batch 4768 Loss: 3.7175
  Batch 4772 Loss: 4.0442
  Batch 4776 Loss: 3.2608
  Batch 4780 Loss: 3.7020
  Batch 4784 Loss: 3.1056
  Batch 4788 Loss: 3.7699
  Batch 4792 Loss: 3.4058
  Batch 4796 Loss: 2.9211
  Batch 4800 Loss: 3.2094
  Batch 4804 Loss: 3.3499
  Batch 4808 Loss: 3.5389
  Batch 4812 Loss: 3.5714
  Batch 4816 Loss: 3.4053
  Batch 4820 Loss: 3.5071
  Batch 4824 Loss: 3.7897
  Batch 4828 Loss: 3.3358
  Batch 4832 Loss: 3.9339
  Batch 4836 Loss: 3.6936
  Batch 4840 Loss: 3.0011
  Batch 4844 Loss: 3.2016
  Batch 4848 Loss: 3.5203
  Batch 4852 Loss: 3.2450
  Batch 4856 Loss: 3.2266
  Batch 4860 Loss: 3.7600
  Batch 4864 Loss: 3.8229
  Batch 4868 Loss: 3.3350
  Batch 4872 Loss: 3.6646
  Batch 4876 Loss: 3.2712
  Batch 4880 Loss: 2.4927
  Batch 4884 Loss: 4.5547
  Batch 4888 Loss: 2.9719
  Batch 4892 Loss: 3.2821
  Batch 4896 Loss: 3.6280
  Batch 4900 Loss: 3.4526
  Batch 4904 Loss: 3.3803
  Batch 4908 Loss: 3.7300
  Batch 4912 Loss: 2.9605
  Batch 4916 Loss: 3.5261
  Batch 4920 Loss: 3.0623
  Batch 4924 Loss: 3.9441
  Batch 4928 Loss: 3.4167
  Batch 4932 Loss: 3.2885
  Batch 4936 Loss: 3.3741
  Batch 4940 Loss: 2.9331
  Batch 4944 Loss: 2.7703
  Batch 4948 Loss: 3.2905
  Batch 4952 Loss: 3.4317
  Batch 4956 Loss: 3.7550
  Batch 4960 Loss: 3.3555
  Batch 4964 Loss: 3.6251
  Batch 4968 Loss: 3.7638
  Batch 4972 Loss: 3.5147
  Batch 4976 Loss: 3.9857
  Batch 4980 Loss: 3.1617
Traceback (most recent call last):
  File "c:\Users\LydoSr\Desktop\multimodal-llm\train.py", line 125, in <module>
    train()
  File "c:\Users\LydoSr\Desktop\multimodal-llm\train.py", line 91, in train
    scaler.scale(loss).backward()
  File "C:\Users\LydoSr\anaconda3\envs\multimod\Lib\site-packages\torch\_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "C:\Users\LydoSr\anaconda3\envs\multimod\Lib\site-packages\torch\autograd\__init__.py", line 289, in backward
    _engine_run_backward(
  File "C:\Users\LydoSr\anaconda3\envs\multimod\Lib\site-packages\torch\autograd\graph.py", line 769, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
